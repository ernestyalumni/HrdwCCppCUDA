% file: HrdwCCppCUDA_grande.tex
% Computational Physics (notes), in unconventional ``grande'' format; fitting a widescreen format
% 
% github        : ernestyalumni
% gmail         : ernestyalumni 
% linkedin      : ernestyalumni 
% wordpress.com : ernestyalumni
%
% This code is open-source, governed by the Creative Common license.  Use of this code is governed by the Caltech Honor Code: ``No member of the Caltech community shall take unfair advantage of any other member of the Caltech community.'' 

\documentclass[10pt]{amsart}
\pdfoutput=1
%\usepackage{mathtools,amssymb,lipsum,caption}
\usepackage{mathtools,amssymb,caption}


\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage[table]{xcolor}
\usepackage{pdfpages}
\usepackage{tikz}
\usetikzlibrary{matrix,arrows}

\usepackage{multicol}

\hypersetup{colorlinks=true,citecolor=[rgb]{0,0.4,0}}

\oddsidemargin=15pt
\evensidemargin=5pt
\hoffset-45pt
\voffset-55pt
\topmargin=-4pt
\headsep=5pt
\textwidth=1120pt
\textheight=595pt
\paperwidth=1200pt
\paperheight=700pt
\footskip=40pt








\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
%\newtheorem*{main}{Main Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}

\newtheorem{definition}{Definition}
\newtheorem{remark}{Remark}

\newenvironment{claim}[1]{\par\noindent\underline{Claim:}\space#1}{}
\newenvironment{claimproof}[1]{\par\noindent\underline{Proof:}\space#1}{\hfill $\blacksquare$}

%This defines a new command \questionhead which takes one argument and
%prints out Question #. with some space.
\newcommand{\questionhead}[1]
  {\bigskip\bigskip
   \noindent{\small\bf Question #1.}
   \bigskip}

\newcommand{\problemhead}[1]
  {
   \noindent{\small\bf Problem #1.}
   }

\newcommand{\exercisehead}[1]
  { \smallskip
   \noindent{\small\bf Exercise #1.}
  }

\newcommand{\solutionhead}[1]
  {
   \noindent{\small\bf Solution #1.}
   }


  \title[Hardware (Compilers, OS, runtime) and C, C++, to CUDA]{Hardware (Compilers, OS, runtime) and C, C++, to CUDA}
\author{Ernest Yeung \href{mailto:ernestyalumni@gmail.com}{ernestyalumni@gmail.com}}
\date{1 Nov 2017}
\keywords{C, C++, CUDA, CUDA C/C++, Compilers, OS, runtime, classes, Object Oriented Programming, Segmentation Fault, memory, memory addresses}

\begin{document}

\definecolor{darkgreen}{rgb}{0,0.4,0}
\lstset{language=C++,
  keywordstyle=\color{blue},
  stringstyle=\color{red},
 commentstyle=\color{darkgreen}
 }
%\lstlistoflistings

\maketitle

\tableofcontents


\begin{multicols*}{2}

\begin{abstract}
I review what, how, and why Segmentation Fault is and occurs in the specific context of C and hopefully to CUDA, virtual memory addresses in C++, and to CUDA.  


\end{abstract}

\section{Introduction; why I'm writing this}  

I didn't realize the importance of having a profound understanding of C/C++ and its relation to hardware, in particular memory (addresses), until I learned more specifically about the work done at NVIDIA from its news and job postings.  Coming from a theoretical and mathematical physics background, I wanted to get myself up to speed as fast as possible, provide good textbook and online references, and directly relate these topics, which seem to be classic topics in computer science (at hardware level) and electrical engineering, to CUDA, to specifically GPU parallel programming with direct CUDA examples.  

Note that there is a version of this LaTeX/pdf file in the usual "letter" format that is exactly the same as the content here, \verb|HrdwCCppCUDA.pdf|.  

Meyer (1997) \cite{Meye1997}


\begin{quotation}
"When programmers first began giving up assembly language in favor of using HLLs, they generally understood the low-level ramifications of the HLL statements they were using and could choose their HLL statements appropriately.Unfortunately, the generation of computer programmers that followed them did not have the benefit of mastering assembly language. As such, they were not in a position to wisely choose statements and data structures that HLLs could efficiently translate into machine code."  
\end{quotation}
pp. 2, Ch. 1 of Hyde (2006) \cite{Hyde2006}, where HLL stands for high-level language.  I was part of that generation and knew of nothing of assembly.  

\section{80x86 Assembly; 80x86 Architecture}  

cf. Ch. 3 of Hyde (2006) \cite{Hyde2006}

Main difference between complex instruction set computer (CISC) architectures such as 80x86 and reduced instruction set computer (RISC) architectures like PowerPC is the way they use memory.  RISC provde relatively clumsy memory access, and applications avoid accessing memory.  80x86 access memory in many different ways and applications take advantage of these facilities.  

\subsection{Basic 80x86 Architecture}  

Intel CPU generally classified as a \emph{Von Neumann machine}, containing 3 main building blocks:
\begin{enumerate}
	\item CPU
	\item memory
	\item input/output (I/O) devices
\end{enumerate}
These 3 components are connected together using the \emph{system bus}.  System bus consists of 
\begin{itemize}
	\item address bus
	\item data bus
	\item control bus
\end{itemize}

CPU communicates with memory and I/O devices by placing a numeric value on the address bus to select 1 of the memory locations or I/O device port locations, each of which has a unique binary numeric address.   \\
Then the CPU, I/O, and memory devices pass data among themselves by placing data on the data bus.   \\
Control bus contains signals that determine the direction of data transfer (to or from memory, and to or from an I/O device).  

So 
\[
\begin{gathered}
\begin{gathered}
\textbf{Memory} \\
\text{Obj}{(\textbf{Memory})} = \text{ memory locations } 
\end{gathered} \\ 
\begin{gathered}
\textbf{I/O} \\
\text{Obj}{(\textbf{I/O})} = \text{ I/O device port locations } 
\end{gathered}
\end{gathered}
\]
and 
\[
\begin{gathered}
\textbf{address bus} \\
\text{Obj}{(\textbf{address bus})} = \text{ unique binary numeric addresses } 
\end{gathered}
\]

Likewise, 
\[
\begin{gathered}
\textbf{data bus} \\
\text{Obj}{(\textbf{data bus})} = \text{ data } 
\end{gathered}
\]

And so
\[
\begin{gathered}
\text{CPU} : \textbf{Memory} \times \textbf{address bus} \to \text{Hom}{(\textbf{Memory} , \textbf{address bus}) } \\ 
	\text{CPU}: (\text{memory location} , \text{unique binary numeric address}) \mapsto \&
\end{gathered}
\]
in the language of category theory.  

\subsection{Registers (for 80x86)}  

cf. 3.3 Basic 80x86 Architecture, from pp. 23 of Hyde (2006) \cite{Hyde2006}.  

Example: to add 2 variables, $x,y$ and store $x+y$ into $z$, you must load 1 of the variables into a register, add the 2nd. operand to the register, and then store register's value into destination variable.  "Registers are middlemen in almost every calculation." Hyde (2006) \cite{Hyde2006}.  
    

 There are 4 categories of 80x86 CPU registers: 
 \begin{itemize}
 	\item general-purpose
 	\item special-purpose application-accessible
 	\item segment
 	\item special-purpose kernel-mode
 \end{itemize}
Segment registers not used very much in modern 32-bit operating systems (e.g. Windows, Linux; what about 64-bit?) and special-purpose kernel-mode registers are intended for writing operating systems, debuggers, and other system-level tools.  

\subsubsection{80x86 General-Purpose Registers}  

80x86 CPUs provide several general-purpose registers, including 8 32-bit registers having the following names: (8 bits in 1 byte, 32-bit is 4 bytes)

\[
EAX, EBX, ECX, EDX, ESI, EDI, EBP, ESP
\]
where E is \emph{extended}; 32-bit registers distinguished from 8 16-bit registers with following names 

\[
AX, BX, CX, DX, SI, DI, BP, SP
\]
and finally 

\[
AL, AH, BL, BH, CL, CH, DL, DH
\]
Hyde says that it's important to note about the general-purpose registers is they're not independent.  80x86 doesn't provide 24 separate registers, but overlaps the 32-bit registers with 16-bit registers, and overlaps 16-bit registers with 8-bit registers.  e.g.

\[
\begin{gathered}
\&AL \neq \&AH, \text{ but } \\
\&AL, \&AH \in \&AX \text{and } \&AX \in \&EAX, \text{ so that } \\
\&AL , \&AH, \&AX \in \&EAX
\end{gathered}
\]

\section{Compilers; Compiler Operation and Code Generation}

cf. Ch. 5 Compiler Operation and Code Generation, from pp. 62 and pp. 72- of Hyde (2006) \cite{Hyde2006}


\section{gdp; good debugging processes (in C/C++/CUDA)}

\href{https://youtu.be/heEaKf2b1uA}{Learn C the hard way Lecture 4, Using Debugger (GDB) }


\section{Pointers in C; Pointers in C categorified (interpreted in Category Theory) and its relation to actual, physical, computer memory and (memory) addresses ((address) bus; pointers, structs, arrays in C}

From Shaw (2015) \cite{Shaw2015}, Exercise 15, 

e.g. \verb|ages[i]|, You're indexing into array \verb|ages|, and you're using the number that's held in $i$ to do it:  
\[
\begin{aligned}
& a : \mathbb{Z} \to \text{Type} \in \textbf{Type}  \\
& a: i \mapsto a[i]
\end{aligned} \text{ e.g. } 
\begin{aligned}
& a: \mathbb{Z} \to \mathbb{R} \text{ or } \mathbb{Z}  \\
& a:i \mapsto a[i]
\end{aligned}
\]

Index $i\in \mathbb{Z}$ is a location \emph{inside} \verb|ages| or $a$, which can also be called \emph{address}.  Thus, $a[i]$.  

Indeed, from \href{http://en.cppreference.com/w/cpp/language/operator_member_access}{cppreference for Member access operators}, 

Built-in \emph{subscript} operator provides access to an object pointed-to by pointer or array operand.  And so \verb|E1[E2]| is exactly identical to \verb|*(E1+E2)|.  


To C, e.g. \verb|ages|, or $a$, is a location in computer's memory where, e.g., all these integers (of \verb|ages|) start, i.e. where $a$ starts.  

\[
\begin{aligned}
& \textbf{Memory} , \qquad \, \text{Obj}{(\textbf{Memory})} \ni \text{ memory location.  Also, to specify CPU, } \\ 
& \textbf{Memory}_{CPU} , \qquad \, \text{Obj}{(\textbf{Memory}_{CPU})} \ni \text{ computer memory location }
\end{aligned}
\]

It's \emph{also} an address, and C compiler will replace e.g. \verb|ages| or array $a$, anywhere you type it, with address of very 1st integer (or 1st element) in, e.g. \verb|ages|, or array $a$.  

\[
\begin{gathered}
\begin{aligned}
\textbf{Arrays} & \xleftrightarrow{ \cong } \textbf{address}  \\
\text{Obj}{(\textbf{Arrays} )} & \xleftrightarrow{ \cong } \text{Obj}{(\textbf{address} )}  \\
a & \xleftrightarrow{ \cong } \verb|0x17|  \\
\end{aligned}
\end{gathered}
\]

"But here's the trick": e.g. "\verb|ages| is an address inside the \emph{entire computer}." (Shaw (2015) \cite{Shaw2015}).  

It's not like $i$ that's just an address inside \verb|ages|.  \verb|ages| array name is actually an address in the computer.     

"This leads to a certain realization: C thinks your whole computer is 1 massive array of bytes."  

"What C does is layer on top of this massive array of bytes the concept of types and sizes of those types." (Shaw (2015) \cite{Shaw2015}).  


Let 
\[
\begin{gathered}
\begin{aligned}
& \textbf{Memory}_{CPU} := 1 \text{ massive array of bytes } \\
& \text{Obj}{(\textbf{Memory}_{CPU})} 
\end{aligned}  \qquad \, \qquad \, 
\begin{aligned}
& \textbf{Type} \\
& \text{Obj}{(\textbf{Type})} \ni \verb|int|, \verb|char|, \verb|float| \\
& \text{Obj}{(\textbf{Type})}  \xrightarrow{\texttt{sizeof}} \mathbb{Z}^+  \\
& T \xmapsto{ \texttt{sizeof} } \verb|sizeof|(T) \\
& \verb|float| \xmapsto{ \texttt{sizeof}} \verb|sizeof|(\verb|float|)
\end{aligned}
\end{gathered}
\]


How C is doing the following with your arrays:  

\begin{itemize}
	\item \emph{Create} a block of memory inside your computer:  
	\[
	\text{Obj}{(\textbf{Memory}_{CPU})} \supset \text{ Memory block }  
	\]
	Let $\text{Obj}{(\textbf{Memory}_{CPU})}$ be an ordered set.  Clearly, then memory can be indexed.  Let $b\in \mathbb{Z}^+$ be this index.  Then Memory block(0) $= \text{Obj}{(\textbf{Memory}_{CPU})}(b)$.  		
	\item \emph{Pointing} the name \verb|ages|, or $a$, to beginning of that (memory) block.  
	
	Entertain, possibly, a category of pointers, $\textbf{Pointers} \equiv \textbf{ptrs}$.  
	\[
	\begin{gathered}
	\textbf{ptrs} \\
	\text{Obj}{(\textbf{ptrs})} \ni a, \text{ e.g. } \verb|ages|  
	\end{gathered}
	\]	
	\[
	\begin{gathered}
	a \mapsto \text{Memory block}(0) \\ 
	\text{Obj}{(\textbf{ptrs})} \to \text{Obj}{(\textbf{Memory}_{CPU})}
	\end{gathered}
	\]
	\item \emph{indexing} into the block, by taking the base address of \verb|ages|, or $a$ 
\end{itemize}

\[
\begin{gathered}
\begin{aligned}
&	a \xmapsto{ \cong } \text{ base address $0x17$ } \\
&	\text{Obj}{((T)\textbf{array})} \xrightarrow{ \cong } \text{Obj}{(\textbf{addresses})}  \\	
&	a[i] \equiv a+i \xmapsto{ \cong } \text{ base address + i * } \verb|sizeof|(T)  \xmapsto{ * } a[i] \in T \text{ where $T$, e.g. $T = \mathbb{Z},\mathbb{R}$ } \\ 
& \text{Obj}{((T)\textbf{array}} \xrightarrow{ \cong } \text{Obj}{(\textbf{addresses})} \to T  
\end{aligned}
\end{gathered}
\]

"A pointer is simply an address pointing somewhere inside computer's memory with a type specifier."  Shaw (2015) \cite{Shaw2015}


C knows where pointers are pointing, data type they point at, size of those types, and how to get the data for you.  

\subsubsection{Practical Pointer Usage}
\begin{itemize}
	\item Ask OS for memory block (chunk of memory) and use pointer to work with it.  This includes strings and \verb|structs|.  
	\item Pass by reference - pass large memory blocks (like large structs) to functions with a pointer, so you don't have to pass the entire thing to the function.  
	\item Take the address of a function, for dynamic callback. (function of functions)
\end{itemize}

"You should go with arrays whenever you can, and then only use pointers as performance optimization if you absolutely have to."  Shaw (2015) \cite{Shaw2015}

\subsubsection{Pointers are not Arrays}  

No matter what, pointers and arrays are not the same thing, even though C lets you work with them in many of the same ways.  

From Eli Bendersky's website, \href{https://eli.thegreenplace.net/2009/10/21/are-pointers-and-arrays-equivalent-in-c}{Are pointers and arrays equivalent in C?}

He also emphasizes that 

\subsubsection{Variable names in C are just labels}  

"A variable in C is just a convenient, alphanumeric pseudonym of a memory location." (Bendersky, \cite{Bend}).  What a compiler does is, create label in some memory location, and then access this label instead of always hardcoding the memory value.   

"Well, actually the address is not hard-coded in an absolute way because of loading and relocation issues, but for the sake of this discussion we don't have to get into these details." (Bendersky, \cite{Bend}) (EY : 20171109 so it's on the address bus?)

Compiler assigns label \emph{at compile time}.  Thus, the great difference between arrays and pointers in C.  

\subsubsection{Arrays passed to functions are converted to pointers}  

cf. Bendersky, \cite{Bend}.  

Arrays passed into functions are always converted into pointers.  The argument declaration \verb|char arr_place[]| in  

\begin{lstlisting}
void foo(char arr_arg[], char* ptr_arg)
{
	char a = arr_arg[7];
	char b = ptr_arg[7];
}
\end{lstlisting} 

is just syntactic sugar to stand for \verb|char* arr_place|.  

From Kernighan and Ritchie (1988) \cite{KeRi1988}, pp. 99 of Sec. 5.3, Ch. 5 Pointers and Arrays,  

\begin{quotation}
	When an array name is passed to a function, what is passed is the location of the initial element.  Within the called function, this argument is a local variable, and so an array name parameter is a pointer, that is, a variable containing an address.  
	\end{quotation}

Why?  

The C compiler has no choice here, since, \\
array name is a label the C compiler replaces \emph{at compile time}  with the address it represents (which for arrays is the address of the 1st element of the array).  

But function isn't called at compile time; it's called \emph{at run time}.  \\
At run time, (where) something should be placed on the stack to be considered as an argument.  

Compiler cannot treat array references inside a function as labels and replace them with addresses, because it has no idea what actual array will be passed in at run time.  

EY : 20171109 It can't anticipate the exact arguments that'll it be given \emph{at run-time}; at the very least, my guess is, it's given instructions.  

Bendersky \cite{Bend} concludes by saying the difference between arrays and pointers does affect you.  One way is how arrays can't be manipulated the way pointers can.  Pointer arithmetic isn't allowed for arrays and assignment to an array of a pointer isn't allowed.  cf. van der Linden (1994) \cite{Vand1994}. Ch. 4, 9, 10.  

Bendersky \cite{Bend} has this one difference example, "actually a common C gotcha":  

"Suppose one file contains a global array:"  

\begin{lstlisting}
char my_Arr[256]  
\end{lstlisting}

Programmer wants to use it in another file, \emph{mistakingly} declares as  
\begin{lstlisting}
extern char* my_arr; 
\end{lstlisting}

When he tries to access some element of the array using this pointer, he'll most likely get a segmentation fault or a fatal exception (nomenclature is OS-dependent).  

To understand why, Bendersky \cite{Bend} gave this hint:  look at the assembly listing  

\begin{lstlisting}
    char a = array_place[7];

0041137E  mov  al,byte ptr [_array_place+7 (417007h)]
00411383  mov  byte ptr [a],al

char b = ptr_place[7];

00411386  mov  eax,dword ptr [_ptr_place (417064h)]
0041138B  mov  cl,byte ptr [eax+7]
0041138E  mov  byte ptr [b],cl
\end{lstlisting}

or my own, generated from \verb|gdb| on Fedora 25 Workstation Linux:

\begin{lstlisting}
0x00000000004004b1 <main+11>:	movzbl 0x200b8f(%rip),%eax        # 0x601047 <array_place+7>
0x00000000004004b8 <main+18>:	mov    %al,-0x1(%rbp)

0x00000000004004bb <main+21>:	mov    0x200be6(%rip),%rax        # 0x6010a8 <ptr_place>
0x00000000004004c2 <main+28>:	movzbl 0x7(%rax),%eax
0x00000000004004c6 <main+32>:	mov    %al,-0x2(%rbp)
\end{lstlisting}

"How will the element be accessed via the pointer?  What's going to happen if it's not actually a pointer but an array?"  Bendersky \cite{Bend}   

EY : 20171106.  Instruction-level, the pointer has to     
\begin{itemize}
	\item \verb|mov    0x200be6(%rip),%rax| - 1st., copy value of the pointer (which holds an address), into \verb|%rax| register.  
	\item \verb|movzbl 0x7(%rax),%eax| - off that address in register `%rax`, offset by 7 (or whatever the offset would be) and get value ther with \verb|%eax| register/instruction  
	\item \verb|mov    %al,-0x2(%rbp)| - \verb|mov| contents \verb|-0x2(%rbp)|into register \verb|%al|
\end{itemize}

If it's not actually a pointer, but an array, the value is copied into the \verb|%rax| register is an actual \verb|char| (or \verb|float|, some type).  \emph{Not} an address that the registers may have been expecting!  

\subsection{Structs in C}
From Shaw (2015) \cite{Shaw2015}, Exercise 16, 

\verb|struct| in C is a collection of other data types (variables) that are stored in 1 block of memory.  You can access each variable independently by name.  

\begin{itemize}
	\item The \verb|struct| you make, i.e.g \verb|struct Person| is now a \emph{compound data type}, meaning you can refer to \verb|struct Person| using the same kinds of expressions you would for other (data) types.
	\item This lets you pass the whole \verb|struct| to other functions
	\item You can access individual members of \verb|struct| by their names using \verb|x->y| if dealing with a ptr.  
\end{itemize}  

If you didn't have \verb|struct|, you'd have to figure out the size, packing, and location of memory of the contents.  In C, you'd let it handle the memory structure and structuring of these compound data types, \verb|struct|s.  (Shaw (2015) \cite{Shaw2015})



\part{C, Stack, Heap Memory Management in C}

\section{C, Stack and Heap Memory Management, Heap and Stack Memory Allocation}  

cf. Ex. 17 of Shaw (2015) \cite{Shaw2015}

Consider chunk of RAM called stack, another chunk of RAM called heap.  Difference between heap and stack depends on where you get the storage.  

Heap is all the remaining memory on computer.  Access it with \verb|malloc| to get more.  \\
Each time you call \verb|malloc|, the OS uses internal functions (EY : 20171110 address bus or overall system bus?) to register that piece of memory to you, then returns ptr to it.  

When done, use \verb|free| to return it to OS so OS can use it for other programs.  Failing to do so will cause program to \emph{leak} memory.  (EY: 20171110, meaning this memory is unavailable to the OS?)

Stack, on a special region of memory, stores temporary variables, which each function creates as locals to that function.  How stack works is that each argument to function is \emph{pushed} onto stack and then used inside the function.  Stack is really a stack data structure, LIFO (last in, first out).  This also happens with all local variables in \verb|main|, such as \verb|char action|, \verb|int id|.  The advantage of using stack is when function exits, \emph{C compiler} pops these variables off of stack to clean up.  

Shaw's mantra: If you didn't get it from \verb|malloc|, or a function that got it from \verb|malloc|, then it's on the stack.  

3 primary problems with stacks and heaps: 
\begin{itemize}
	\item If you get a memory block from \verb|malloc|, and have that ptr on the stack, then when function exits, ptr will get popped off and lost.  
	\item If you put too much data on the stack (like large structs and arrays), then you can cause a \emph{stack overflow} and program will abort.  Use the heap with \verb|malloc|.  
	\item If you take a ptr, to something on stack, and then pass or return it from your function, then the function receiving it will \emph{segmentation fault}, because actual data will get popped off and disappear.  You'll be pointing at dead space.  
\end{itemize}
cf. Ex. 17 of Shaw (2015) \cite{Shaw2015}

\section{Data segments; Towards Segmentation Fault}

cf. Ferres (2010) \cite{Ferr2010}

When program is loaded into memory, it's organized into 3 \emph{segments} (3 areas of memory):  
let executable program generated by a compiler (e.g. \verb|gcc|) be organized in memory over a range of addresses (EY : 20171111 assigned to physical RAM memory by address bus?), ordered, from low address to high address.  
\begin{itemize}
	\item \emph{text} segment or code segment - where compiled code of program resides (from lowest address); code segment contains code executable or, i.e. code binary.  

	As a memory region, text segment may be placed below heap, or stack, in order to prevent heaps and stack overflows from overwriting it.  
	
	Usually, text segment is sharable so only a single copy needs to be in memory for frequently executed programs, such as text editors, C compiler, shells, etc.  Also, text segment is often read-only, to prevent program from accidentally modifying its instructions.  	
	cf. \href{http://www.geeksforgeeks.org/memory-layout-of-c-program/}{Memory Layout of C Programs; GeeksforGeeks}  
	\item Data segment:  data segment subdivided into 2 parts:
	\begin{itemize}
		\item initialized data segment - all global, static, constant data stored in data segment. Ferres (2010) \cite{Ferr2010}.  Data segment is a portion of virtual address of a program.  
		
		Note that, data segment not read-only, since values of variables can be altered at run time.  
		
		This segment can also be further classified into initialized read-only area and initialized read-write area.  
		
		e.g. \verb|char s[] = "hello world"| and \verb|int debut = 1| \emph{outside the main (i.e. global)} stored in initialized read-write area.  \\
		\verb|const char *string = "hello world"| in global C statement makes string literal "hello world" stored in initialized read-only area.  Character pointer variable string in initialized read-write area.  
		   cf. \href{http://www.geeksforgeeks.org/memory-layout-of-c-program/}{Memory Layout of C Programs}  
		\item uninitialized data stored in BSS.  Data in this segment is initialized by kernel (OS?) to arithmetic 0 before program starts executing.  
		
		Uninitialized data starts at end of data segment ("largest" address for data segment) and contains all global and static variables initialized to 0 or don't have explicit initialization in source code.  
		
		e.g. \verb|static int i;| in BSS segment.  \\
		e.g. \verb|int j;| global variable in BSS segment. 	
		
		  cf. \href{http://www.geeksforgeeks.org/memory-layout-of-c-program/}{Memory Layout of C Programs}  
			
	\end{itemize}
	\item Heap - "grows upward" (in (larger) address value, begins at end of BSS segment), allocated with \verb|calloc, malloc|, "dynamic memory allocation".    
	
	Heap area shared by all shared libraries and dynamically loaded modules in a process.  
	
	Heap grows when memory allocator invokes \verb|brk()| or \verb|sbrk()| system call, mapping more pages of physical memory into process's virtual address space.  
	
	\item Stack - store local variables, used for passing arguments to functions along with return address of the instruction which is to be executed after function call is over.  
	
	When a new stack frame needs to be added (resulting from a \emph{newly called function}), stack "grows downward."  (Ferres (2010) \cite{Ferr2010})  
	
	Stack grows automatically when accessed, up to size set by kernel (OS?) (which can be adjusted with setrlimit(\verb|RLIMIT_STACK|,$\ldots$ )).  \\
	\end{itemize}

\subsubsection{Mathematical description of Program Memory (data segments), with \textbf{Memory}, \textbf{Addresses}}  

Let $\textbf{Address}$, with $\text{Obj}{(\textbf{Address})} \cong \mathbb{Z}^+$ be an ordered set.  

Memory block $\subset \text{Obj}{(\textbf{Memory})}$, s.t. 
\[
\text{Memory block} \xmapsto{ \cong } \lbrace \text{ low address }, \text{ low address} + \texttt{sizeof}(T) , \dots \text{ high address } \rbrace  \equiv \text{addresses}_{\text{Memory block} } \subset \mathbb{Z}^+
\]
where $T \in \text{Obj}{(\textbf{Types})}$ and $\cong$ assigned by address bus, or the virtual memory table, and $\text{addresses}_{\text{Memory block}} \subset \text{Obj}{(\textbf{Addresses})}$.  

Now, \\
text segment, (initialized) data segment, (uninitialized) data segment, heap, stack, command-line arguments and environmental variables $\subset \text{addresses}_{\text{Memory block}}$, that these so-called data segments are discrete subsets of the set of all addresses assigned for the memory block assigned for the program.  

Now, $\forall \, i \in \text{text segment }, \, \forall \, j \in \text{ (initialized) data segment }$, $i<j$ and $\forall \, j \in \text{ (initialized) data segment }, \, \forall \, k \in \text{ (uninitiaized) data segment }$, $j<k$, and so on.  Let's describe this with the following notation:  

\begin{equation}
\begin{gathered}
\text{text segment} < \text{(initialized) data segment} < \text{(uninitialized) data segment} < \\ 
< \text{heap} < \text{stack} < \text{ command-line arguments and environmental variables}  
\end{gathered}
\end{equation}


Consider stack of variable length $n_{\text{stack}} \in \mathbb{Z}^+$.  Index the stack by $i_{\text{stack}} = 0,1,\dots n_{\text{stack}} - 1$.  "Top of the stack" is towards "decreasing" or "low" (memory) address, so that the relation between "top of stack" to beginning of the stack and high address to low address is \emph{reversed}: 
\[
i_{\text{stack}} \mapsto \text{high address} - i_{\text{stack}}
\]

Call stack is composed of stack frames (i.e. "activation records"), with each stack frame corresponding to a subroutine call that's not yet termined with a routine (at any time).  

The \emph{frame pointer} \verb|FP| points to location where stack pointer was.  

Stack pointer usually is a register that contains the "top of the stack", i.e. stack's "low address" currently, cf. \href{https://www.cs.umd.edu/class/sum2003/cmsc311/Notes/Mips/stack.html}{Understanding the stack}, i.e. 
\begin{equation}
\text{eval}(RSP) = \text{high address} - i_{\text{stack}}
\end{equation}


\subsubsection{Mathematical description of strategy for stack buffer overflow exploitation}

Let $n_{\text{stack}} = n_{\text{stack}}(t)$.  Index the stack with $i_{\text{stack}}$ (from "bottom" of the stack to the "top" of the stack):
\[
0 < i_{\text{stack}} < n_{\text{stack}} - 1
\]
Recall that $i_{\text{stack}} \in \mathbb{Z}^+$ and 
\[
i_{\text{stack}} \mapsto \text{high address } - i_{\text{stack}} \equiv x = x(i_{\text{stack}}) \in \text{Addresses}_{\text{Memory block}} \subset \text{Obj}(\textbf{Address})
\]
Let an array of length $L$ (e.g. \verb|char| array) \verb|buf|, with \verb|\&buf| $=$ \verb|\&buf(0)| $\in  \text{Obj}{(\textbf{Address})}$, be s.t. \verb|&buf| $=x(n_{\text{stack}}-1)$ (starts at "top of the stack and "lowest" address of stack at time $t$, s.t. 
\[
\verb|&buf|(j) = \verb|&buf|(0) + j \verb|sizeof|(T)
\]
with $T\in \textbf{Types}$).  


Suppose return address of a function (such as \verb|main|), $\text{eval}(\verb|RIP|)$ be 
\[
\text{eval}(\verb|RIP|) = \verb|&buf| + L \text{or at least } \text{eval}(\verb|RIP|) \geq \verb|&buf| + L
\]
If we write to \verb|buf| more values than $L$, we can write over \text{eval}(\verb|RIP|), making \text{eval}(\verb|RIP|) a different value than before.  




\subsection{Stack}
cf. Ferres (2010) \cite{Ferr2010}

Stack and functions: When a function executes, it may add some of its state data to top of the stack (EY : 20171111, stack grows downward, so "top" is smallest address?); when function exits, stack is responsible for removing that data from stack.  

In most modern computer systems, each thread has a reserved region of memory, stack.  Thread's stack is used to store location of function calls in order to allow return statements to return to the correct location.  

\begin{itemize}
	\item OS allocates stack for each system-level thread when thread is created.  
	\item Stack is attached to thread, so when thread exits, that stack is reclaimed, vs. heap typically allocated by application at runtime, and is reclaimed when application exits.  
	\item When thread is created, stack size is set.  
	\item Each byte in stack tends to be reused frequently, meaning it tends to be mapped to the processor's cache, making if very fast.  
	\item Stored in computer RAM, \emph{just like} the heap.  
	\item Implemented with an actual stack data structure.  
	\item stores local data, return addresses, used for parameter passing  
	\item Stack overflow, when too much stack is used (mostly from infinite (or too much) recursion, and very large allocation)
	\item Data created on stack can be used without pointers.  
\end{itemize}

Also note, for \textbf{physical location in memory}, because of \href{http://en.wikipedia.org/wiki/Virtual_memory}{Virtual Memory}, makes your program think that you have access to certain addresses where physical data is somewhere else (even on hard disc!).  Addresses you get for stack are in increasing order as your call tree gets deeper.  

\href{http://stackoverflow.com/questions/79923/what-and-where-are-the-stack-and-heap/79988#79988}{memory management - What and where are the stack and heap? Stack Overflow, Tom Leys' answer}

cf. \url{https://stackoverflow.com/questions/79923/what-and-where-are-the-stack-and-heap/80113#80113}  

Stack is memory set aside for a thread of execution.  Each thread gets a stack, while there's typically only 1 heap for the application (although it isn't uncommon to have multiple heaps for different types of allocation).  

"
\begin{quotation}
To what extent are they controlled by the OS or language runtime?
\end{quotation}

The OS allocates the stack for each system-level thread when the thread is created. Typically the OS is called by the language runtime to allocate the heap for the application.

\begin{quotation}
What is their scope?
\end{quotation}

\begin{quotation}
The stack is attached to a thread, so when the thread exits the stack is reclaimed. The heap is typically allocated at application startup by the runtime, and is reclaimed when the application (technically process) exits.
\end{quotation}

\begin{quotation}
What determines the size of each of them?
\end{quotation}

The size of the stack is set when a thread is created. The size of the heap is set on application startup, but can grow as space is needed (the allocator requests more memory from the operating system).




\subsection{Stack overflow}  

If you use heap memory, and you overstep the bounds of your allocated block, you have a decent chance of triggering a segmentation fault (not 100%, since your block may be incidentally contiguous with another that you have previously allocated), says Ferres (2010) \cite{Ferr2010}.  

On stack, since variables created on stack are always contiguous with each other; writing out of bounds can change the value of another variable.  e.g. buffer overflow.  

\subsection{Heap}  

Heap contains a linked list of used and free blocks.  New allocations on the heap (by \verb|new| or \verb|malloc|) are satisfied by creating suitable blocks from free blocks.  

This requires updating list of blocks on the heap.  This meta information about the blocks on the heap is stored \emph{on the heap} often in a small area in front of every block.  

\begin{itemize}
	\item Heap size set on application startup, but can grow as space is needed (allocator requests more memory from OS)
	\item heap, stored in computer RAM, like stack.
\end{itemize}

\subsubsection{Memory leaks}  

Memory leaks occurs when computer program consumes memory, but memory isn't released back to operating system.  

"Typically, a memory leak occurs because dynamically allocated memory becomes unreachable."  (Ferres (2010) \cite{Ferr2010}).  

Programs \verb|./Cmemory/heapstack/Memleak.c| deliberately leaks memory by losing the pointer to allocated memory.  

Note, generally, the OS delays real memory allocation until something is written into it, so program ends when virtual addresses run out of bounds (per process limits).  

\subsection{More Segmentation Faults}  

The operating system (OS) is running the program (its instructions).  Only from the hardware, with \href{https://en.wikipedia.org/wiki/Memory_protection}{memory protection}, with the OS be signaled to a memory access violation, such as writing to read-only memory or writing outside of allotted-to-the-program memory, i.e. data segments.  On \verb|x86_64| computers, this \href{https://en.wikipedia.org/wiki/General_protection_fault}{general protection fault} is initiated by protection mechanisms from the hardware (processor).  From there, OS can signal the fault to the (running) process, and stop it (abnormal termination) and sometimes core dump. 

For \href{https://en.wikipedia.org/wiki/Virtual_memory}{virtual memory}, the memory addresses are mapped by program called \emph{virtual addresses} into \emph{physical addresses} and the OS manages virtual addresses space, hardcare in the CPU called memory management unit (\emph{MMU}) translates virtual addresses to physical addresses, and kernel manages memory hierarchy (eliminating possible overlays).  In this case, it's the \emph{hardware} that detects an attempt to refer to a non-existent segment, or location outside the bounds of a segment, or to refer to location not allowed by permissions for that segment (e.g. write on read-only memory).          

\subsubsection{Dereferencing a ptr to a NULL ptr (in C) at OS, hardware level}

  
The problem, whether it's for dereferencing a pointer that is a null pointer, or uninitialized pointer, appears to (see the \verb|./Cmemory/| subfolder) be at this instruction at the register level:  

\begin{lstlisting}
x000000000040056c <+38>:	movzbl (%rax),%eax

// or 

0x00000000004004be <+24>:	movss  %xmm0,(%rax)  
\end{lstlisting}

involving the register RAX, a temporary register and to return a value, upon assignment.  And in either case, register RAX has trying to access virtual (memory) address \verb|0x0| (to find this out in \verb|gdb|, do \verb|i r| or \verb|info register|).  

Modern OS's run user-level code in a mode, such as \emph{protected mode}, that uses "paging" (using secondary memory source than main memory) to convert virtual addresses into physical addresses.  

For each process (thread?), the OS keeps a \emph{page table} dictating how addresses are mapped.  Page table is stored in memory (and protected, so user-level code can't modify it).  For every memory access, given (memory) address, CPU translates address according to the page table.  

When address translation fails, as in the case that \emph{not all addresses are valid}, and so if a memory access generates an invalid address, the processor (hardware!) raises a \emph{page fault exception}.  "This triggers a transition from \emph{user mode} (aka \emph{current privilege level (CPL) 3} on x86/x86-64) into \emph{kernel mode} (aka CPL 0) to a specific location in the kernel's code, as defined by the \emph{interrupt descriptor table} (IDT)."  cf. [What happens in OS when we dereference a NULL pointer in C?](https://stackoverflow.com/questions/12645647/what-happens-in-os-when-we-dereference-a-null-pointer-in-c)


Kernel regains control and send signal (EY : 20171115 to the OS, I believe).   

In modern OS's, page tables are usually set up to make the address 0 an invalid virtual address.  

cf. [What happens in OS when we dereference a NULL pointer in C?](https://stackoverflow.com/questions/12645647/what-happens-in-os-when-we-dereference-a-null-pointer-in-c)

\part{C++}  

\section{static}



\section{Free Store}  


cf. \href{http://www.gotw.ca/gotw/009.htm}{GotW \#9, Memory Management - Part I}

Free store is 1 of the 2 dynamic memory areas, allocated/freed by new/delete (free store and heap).  Object lifetime can be less than the time the storage is allocated.  

Let $t_{0,\text{obj}}, t_{f,\text{obj}}$, $t_{f,\text{obj}} \geq t_{0,\text{obj}}$, \\
\phantom{Let } $t_{0,\text{alloc}}, t_{f,\text{alloc}}$, $t_{f,\text{alloc}} \geq t_{0,\text{alloc}}$, \\  
with the condition that 
\[
t_{0,\text{alloc}} \leq t_{0,\text{obj}} \leq t_{f,\text{obj}} \leq t_{f,\text{alloc}}
\].  

For $t \in (t_{0,\text{alloc}} , t_{0,\text{obj}} )$, storage may be accessed and manipulated through a \verb|void*| but non of the proto-object's \emph{nonstatic} members or member functions may be accessed, have their addresses taken, or be otherwise manipulated.  




cf. 11.2 Introduction of Ch. 11 Select Operations \cite{Stro2013}.  




\section{Copy vs. Move}  
cf. 17.1 Introduction of Ch. 17 Construction, Cleanup, Copy, and Move of Stroustrup \cite{Stro2013}.  

Difference between \emph{move} and \emph{copy}: after a copy, 2 objects must have same value; whereas after a move, the source of the move isn't required to have its original value.  So moves can be used when source object won't be used again.  

Refs.: Sec. 3.2.1.2, Sec. 5.2, notion of moving a resource, Sec. 13.2-Sec.13.3, object lifetime and errors explored further in Stroustrup \cite{Stro2013}  
  
  
5 situations in which an object is copied or moved:   
\begin{itemize}
	\item as source of an \emph{assignment}
	\item as object initializer 
	\item as function argument
	\item as function return value
	\item as an exception  
\end{itemize}

\section{vtable; virtual table}  

I was given this answer to a question I posed to a 20 year C++ veteran and it was such an important answer (as I did not know a virtual table existed, at all before), that I will copy this, repeat this and explore this extensively:  

"The keyword you're looking for is virtual table: " \href{https://stackoverflow.com/questions/99297/how-are-virtual-functions-and-vtable-implemented}{How are virtual functions and vtable implemented?, stackoverflow}  

Original question, from \href{https://stackoverflow.com/users/3153/brian-r-bondy}{Brian R. Bondy}:  

\subsection{How are virtual functions and vtable implemented?}

We all know what virtual functions are in C++, but how are they implemented at a deep level?

Can the vtable be modified or even directly accessed at runtime?

Does the vtable exist for all classes, or only those that have at least one virtual function?

Do abstract classes simply have a NULL for the function pointer of at least one entry?

Does having a single virtual function slow down the whole class? Or only the call to the function that is virtual? And does the speed get affected if the virtual function is actually overwritten or not, or does this have no effect so long as it is virtual.

Answer from \emph{community wiki}:  

\subsubsection{How are virtual functions implemented at a deep level?}

From \href{http://wayback.archive.org/web/20100209040010/http://www.codersource.net/published/view/325/virtual_functions_in.aspx}{"Virtual Functions in C++"}

Whenever a program has a virtual function declared, a v - table is constructed for the class. The v-table consists of addresses to the virtual functions for classes that contain one or more virtual functions. The object of the class containing the virtual function contains a virtual pointer that points to the base address of the virtual table in memory. Whenever there is a virtual function call, the v-table is used to resolve to the function address. An object of the class that contains one or more virtual functions contains a virtual pointer called the vptr at the very beginning of the object in the memory. Hence the size of the object in this case increases by the size of the pointer. This vptr contains the base address of the virtual table in memory. Note that virtual tables are class specific, i.e., there is only one virtual table for a class irrespective of the number of virtual functions it contains. This virtual table in turn contains the base addresses of one or more virtual functions of the class. At the time when a virtual function is called on an object, the vptr of that object provides the base address of the virtual table for that class in memory. This table is used to resolve the function call as it contains the addresses of all the virtual functions of that class. This is how dynamic binding is resolved during a virtual function call.

cf. \href{http://wayback.archive.org/web/20100209040010/http://www.codersource.net/published/view/325/virtual_functions_in.aspx}{"Virtual Functions in C++"}

\subsubsection{What is a Virtual Function?}  

A virtual function is a member function of a class, whose functionality can be over-ridden in its derived classes. It is one that is declared as virtual in the base class using the virtual keyword. The virtual nature is inherited in the subsequent derived classes and the virtual keyword need not be re-stated there. The whole function body can be replaced with a new set of implementation in the derived class. 

\subsubsection{What is Binding?}  

Binding is associating an object or a class with its member.   If we call a method \verb|fn()| on an object \verb|o| of a class \verb|c|, we say that object \verb|o| is binded with method \verb|fn()|.  

This happens at \emph{compile time} and is known as \emph{static} - or \emph{compile-time} binding.   

Calls to virtual member functions are resolved during \emph{run-time}.  This mechanisms is known as \emph{dynamic-binding.}   

The most prominent reason why a virtual function will be used is to have a different functionality in the derived class.  The difference between a non-virtual member function and a virtual member function is, the non-virtual member functions are resolved at compile time.  

\subsubsection{How does a Virtual Function work?}  

When a program (code text?) has a virtual function declared, a \textbf{v-table} is \emph{constructed} for the class.  

The v-table consists of addresses to virtual functions for classes that contain 1 or more virtual functions.  \\
The object of the class containing the virtual function \emph{contains a virtual pointer} that points to the base address of the virtual table in memory.  An object of the class that contains 1 or more virtual functions contains a virtual pointer called the \textbf{vptr} at the very beginning of the object in the memory.  (Hence size of the object in this case increases by the size of the pointer; "memory/size overhead.")  \\
Whenever there's a virtual function call, vtable is used to resolve to the function address.  
This vptr contains base address of the virtual table in memory.  \\

Note that virtual tables are class specific, i.e. there's only 1 virtual table for a class, irrespective of number of virtual functions it contains.  

This virtual table in turn contains base addresses of 1 or more virtual functions of the class.  

At the time when a virtual function is called on an object, the vptr of that object provides the base address of the virtual table for that class in memory.  This table is used to resolve the function call as it contains the addresses of all the virtual functions of that class.  This is how dynamic binding is resolved during a virtual function call.  





\end{multicols*}

\begin{thebibliography}{9}
\bibitem{Meye1997}
Bertrand Meyer. \textbf{Object-Oriented Software Construction} (Book/CD-ROM) (2nd Edition) 2nd Edition.   Prentice Hall; 2 edition (April 13, 1997).  ISBN-13: 978-0136291558

\bibitem{Hyde2004}
Randall Hyde.  \textbf{Write Great Code: Volume 1: Understanding the Machine} October 25, 2004.  No Starch Press; 1st edition (October 25, 2004).  ISBN-13: 978-1593270032

\bibitem{Hyde2006}
Randall Hyde.  \textbf{Write Great Code, Volume 2: Thinking Low-Level, Writing High-Level}.   1st Edition.  No Starch Press; 1 edition (March 18, 2006).  ISBN-13: 978-1593270650

\bibitem{Shaw2015}
Zed A. Shaw.  \textbf{Learn C the Hard Way: Practical Exercises on the Computational Subjects You Keep Avoiding (Like C)} (Zed Shaw's Hard Way Series) 1st Edition.  Addison-Wesley Professional; 1 edition (September 14, 2015) ISBN-13: 978-0321884923.  

\bibitem{Bend}
Eli Bendersky.   \href{https://eli.thegreenplace.net/2009/10/21/are-pointers-and-arrays-equivalent-in-c}{Are pointers and arrays equivalent in C?}

\bibitem{KeRi1988}
Brian W. Kernighan, Dennis M. Ritchie.  \textbf{C Programming Language}, 2nd Ed. 1988.   

\bibitem{Vand1994}
Peter van der Linden.  \textbf{Expert C Programming: Deep C Secrets} 1st Edition.  Prentice Hall; 1st edition (June 24, 1994)  ISBN-13: 978-0131774292

\bibitem{Ferr2010}
Leo Ferres.  "Memory management in C: The heap and the stack".  \href{http://www.inf.udec.cl/~leo/teoX.pdf}{Memory management in C: The heap and the stack}


\bibitem{Stro2013}
Bjarne Stroustrup.  \textbf{The C++ Programming Language}, 4th Edition. Addison-Wesley Professional; 4 edition (May 19, 2013).  ISBN-13: 978-0321563842

\bibitem{GhJa1997} 
Carlo Ghezzi, Mehdi Jazayeri.  \textbf{Programming Language Concepts} 3rd Edition.  Wiley; 3 edition (June 23, 1997).  ISBN-13: 978-0471104261  \url{https://vowi.fsinf.at/images/7/72/TU_Wien-Programmiersprachen_VL_(Puntigam)_-_E-Book_SS08.pdf}



\end{thebibliography}

\end{document}



